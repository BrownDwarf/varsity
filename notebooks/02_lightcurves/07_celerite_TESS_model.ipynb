{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GPs to TESS data\n",
    "\n",
    "Can a damped, driven simple harmonic oscillator model the TESS data effectively?  To what extent can multiple peaks be explained as phase drift?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.stats import LombScargle\n",
    "import astropy.units as u\n",
    "from astropy.time import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import celerite\n",
    "from celerite import terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightkurve as lk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve custom-made lightkurve data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll retrieve the custom made lightcurve that we saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_raw = lk.TessLightCurve.read('../data/TESS/lightkurve_custom_4pixel.fits', format='tess').normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = lc_raw.flux/lc_raw.flux_err\n",
    "np.round(np.percentile(snr, (5, 50, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1L, threshold1R = 1572, 1581.7\n",
    "threshold2L, threshold2R = 1585, 1595.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc_raw.plot();\n",
    "#ax.set_ylim(0.85, 1.1)\n",
    "ax.axvline(threshold1L, color='#e67e22');ax.axvline(threshold1R, color='#e67e22');\n",
    "ax.axvline(threshold2L, color='#e67e22');ax.axvline(threshold2R, color='#e67e22');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal-to-noise ratio is typically better than 100 per pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim the noisy parts when the telescope is thermally settling.\n",
    "Between the two sets of vertical lines above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (lc_raw.time.value > threshold1L) & (lc_raw.time.value < threshold1R)\n",
    "mask2 = (lc_raw.time.value > threshold2L) & (lc_raw.time.value < threshold2R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just look at one segment for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lc_raw[mask1 | mask2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.time.min().iso, lc.time.max().iso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the Power Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the power spectrum separately for each campaign.  This approach allows us to not worry about the mean level that we assign to each campaign, and it helps see which PSD structures persist from campaign to campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = lc.to_periodogram(normalization='psd', freq_unit=1/u.day, oversample_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_noise = lc.copy()\n",
    "lc_noise.flux = np.random.normal(1, scale=lc.flux_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc_noise.plot(label='Noise')\n",
    "lc.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_noise = lc_noise.to_periodogram(normalization='psd', freq_unit=1/u.day, oversample_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws = 251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_period = 5.28 * u.hour\n",
    "peak_frequency = (1.0/(peak_period.to(u.day)))\n",
    "\n",
    "alt_period = 6.94 * u.hour\n",
    "alt_frequency = 1.0/(alt_period.to(u.day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a noise region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_power_draws = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_draws):\n",
    "    lc_noise = lc.copy()\n",
    "    lc_noise.flux = np.random.normal(1, scale=lc.flux_err)\n",
    "    pg_noise = lc_noise.to_periodogram(normalization='psd', freq_unit=1/u.day, oversample_factor=10)\n",
    "    pg_noise.plot(ax=ax, scale='log', label=None, alpha=0.1, color='#c0392b')\n",
    "    noise_power_draws.append(pg_noise.power.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, med, hi = np.percentile(noise_power_draws, (15.9, 50.0, 84.1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pg.plot(scale='log', zorder=10)\n",
    "ax.set_ylim(med.mean()/3);\n",
    "ax.axvline(peak_frequency.value, color='#2980b9', linestyle='dashed', \n",
    "           label='$P_B = $ {:0.3f}'.format(peak_period),linewidth=0.8)\n",
    "ax.axvline(peak_frequency.value*2, color='#2980b9', linestyle='dotted', \n",
    "           label='$P_B \\; /\\; 2$'.format(peak_period/2),linewidth=0.8)\n",
    "ax.axvline(alt_frequency.value, color='#27ae60', linestyle='solid', \n",
    "           label='{:0.3f} (maybe $P_A$)'.format(alt_period),linewidth=0.8)\n",
    "ax.axhline(med.mean(), color='#f1c40f', linestyle='dashed', label='Typical Noise Floor', zorder=-1)\n",
    "\n",
    "#plt.plot(pg.frequency, med, color='#95a5a6')\n",
    "\n",
    "pg_noise.plot(ax=ax, scale='log', label='Noise draw', color='#e67e22')\n",
    "\n",
    "plt.fill_between(pg.frequency, lo, hi, color='#f39c12', alpha=0.2, zorder=0)\n",
    "#pg_noise.plot(ax=ax, scale='log', label='Noise Draw', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "ax.set_xlim(pg.frequency[0].value, pg.frequency[-1].value);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lightkurve power scale factor is:  \n",
    "$$ \\tilde P_{lk} = P_{lk} \\cdot \\frac{2 T}{N}$$\n",
    "\n",
    "Where the tilde represents the rescaled, and  \n",
    "$N$ is the number of samples  \n",
    "$T$ is the total observation window duration, in say, days or $\\frac{1}{\\mathrm{Hz}}$\n",
    "\n",
    "The *celeritÃ©* power scale **expects** a rescaling of Lomb Scargle power:\n",
    "$$ \\tilde P_{LS} = P_{LS} \\cdot \\frac{1}{N}$$  \n",
    "*assuming* the `.get_psd()` power is scaled by $ \\tilde P_c = P_c \\cdot \\frac{2}{T}$.\n",
    "\n",
    "So to get them to match up, we can simply divide the lightkurve power by $2T$, **or** multiply the `celerite` power $\\tilde P_c$ by $2T$, yielding: \n",
    "\n",
    "$ \\hat P_c = \\tilde P_c \\cdot 2T = P_c \\cdot \\frac{2}{T}\\cdot 2T =  4P_c $\n",
    "\n",
    "\n",
    "My inclination is to leave lightkurve as perfect, and rescale celerite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = np.var(lc.flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A periodic term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_period = peak_period.to(u.day).value\n",
    "guess_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_guess = 400\n",
    "w0_guess = 2.0*np.pi / guess_period\n",
    "S0_guess = variance /3600\n",
    "\n",
    "bounds1 = dict(log_S0=(np.log(variance/1000000), np.log(variance*100000)),\n",
    "               log_Q=(np.log(3), np.log(1000000)), \n",
    "               log_omega0=(np.log(w0_guess*0.8),np.log(w0_guess*1.2)))\n",
    "\n",
    "kernel_sho = terms.SHOTerm(log_S0=np.log(S0_guess), log_Q=np.log(Q_guess), \n",
    "                       log_omega0=np.log(w0_guess))#, bounds=bounds1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A second periodic term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_period2 = guess_period / 2 # 2.5 / 24.0 * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2_guess = 100\n",
    "w02_guess = 2.0*np.pi / guess_period2\n",
    "S02_guess = variance /9000\n",
    "\n",
    "bounds_sho2 = dict(log_S0=(np.log(variance/10000), np.log(variance*1000)),\n",
    "               log_Q=(np.log(3), np.log(2000)), \n",
    "               log_omega0=(np.log(w02_guess*0.8),np.log(w02_guess*1.2)))\n",
    "\n",
    "kernel_sho2 = terms.SHOTerm(log_S0=np.log(S02_guess), log_Q=np.log(Q2_guess), \n",
    "                       log_omega0=np.log(w02_guess))#, bounds=bounds_sho2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Matern term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">   log_sigma (float): The log of the parameter $\\sigma$.  \n",
    "\n",
    ">    log_rho (float): The log of the parameter $\\rho$.   \n",
    "    \n",
    ">    eps (Optional[float]): The value of the parameter $\\epsilon$.   \n",
    "        (default: `0.01`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_guess = np.sqrt(variance)/10\n",
    "rho_guess =  guess_period2 / 10.0\n",
    "\n",
    "kernel_mat = terms.Matern32Term(log_sigma=np.log(sigma_guess), log_rho=np.log(rho_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Jitter term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_jit = terms.JitterTerm(log_sigma=np.log(lc.flux_err.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_kernel = kernel_sho + kernel_sho2 + kernel_mat #+ kernel_jit\n",
    "gp = celerite.GP(net_kernel, fit_mean=True, mean=lc.flux.mean())\n",
    "gp.compute(lc.time.value, yerr=lc.flux_err.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pg.frequency.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_true = net_kernel.get_psd(2*np.pi*f) * 4\n",
    "power_sho1 = kernel_sho.get_psd(2*np.pi*f) * 4\n",
    "power_sho2 = kernel_sho2.get_psd(2*np.pi*f) * 4\n",
    "power_mat = kernel_mat.get_psd(2*np.pi*f) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_draw = gp.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc.plot()\n",
    "ax.plot(lc.time.value, gp.sample()+0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plausibly in the same ballpark--- good enough for an initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_draw = lc.copy()\n",
    "lc_draw.flux = gp.sample() * lc.flux.unit\n",
    "pg_draw = lc_draw.to_periodogram(normalization='psd', freq_unit=1/u.day, oversample_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pg.plot(scale='log')\n",
    "ax.axvline(1.0/guess_period, color='#ddaaaa', linestyle='dotted', label='{:0.3f} d'.format(guess_period), alpha=1)\n",
    "pg_draw.plot(ax=ax, label='GP Draw', scale='log')\n",
    "ax.step(pg.frequency, power_true, color='#f39c12', lw=2,label=\"Analytic model\", where='mid', zorder=0)\n",
    "\n",
    "ax.plot(f, power_sho1, color='#f39c12', lw=1,label=\"SHO 1\", linestyle='--')\n",
    "ax.plot(f, power_sho2, color='#f39c12', lw=1,label=\"SHO 2\", linestyle=':')\n",
    "ax.plot(f, power_mat, color='#f39c12', lw=1,label=\"Matern\", linestyle='-.')\n",
    "\n",
    "plt.ylim(med.mean()/3)\n",
    "ax.set_xlim(pg.frequency[0].value, pg.frequency[-1].value);\n",
    "plt.legend(loc='best')\n",
    "ax.set_xlim(2, 13)\n",
    "plt.title('Initial Guess PSD');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome!  Let's spot-check our results by making a draw from the model and then computing as if it were data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lc.flux.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the GP model\n",
    "\n",
    "print(\"Initial log-likelihood: {0}\".format(gp.log_likelihood(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_like(params, y, gp1):\n",
    "    gp1.set_parameter_vector(params)\n",
    "    return -gp1.log_likelihood(y)\n",
    "\n",
    "def grad_neg_log_like(params, y, gp1):\n",
    "    gp1.set_parameter_vector(params)\n",
    "    return -gp1.grad_log_likelihood(y)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine the GP parameters with optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "initial_params = gp.get_parameter_vector()\n",
    "bounds = gp.get_parameter_bounds()\n",
    "soln = minimize(neg_log_like, initial_params, jac=grad_neg_log_like,\n",
    "                method=\"L-BFGS-B\", bounds=None, args=(y, gp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Spot check the optimization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.set_parameter_vector(soln.x)\n",
    "print(\"Final log-likelihood: {0}\".format(-soln.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred = np.linspace(lc.time.value[0], lc.time.value[-1], num=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the maximum likelihood prediction\n",
    "mu, var = gp.predict(y, t_pred, return_var=True)\n",
    "std = np.sqrt(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc.plot(drawstyle='steps-mid')\n",
    "ax.step(lc.time.value, gp.sample()+0.1, label='GP Sample', lw=1, linestyle=':')\n",
    "ax.step(t_pred, mu, label='mean prediction', alpha=1, linestyle='dashed')\n",
    "ax.fill_between(t_pred, mu-std, mu+std, label='Confidence region', alpha=0.3)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc.plot(drawstyle='steps-mid', linewidth=2)\n",
    "#ax.step(lc.time.value, gp.sample(), label='GP Sample', lw=1)\n",
    "ax.step(t_pred, mu, label='mean prediction', alpha=1, linestyle='dashed')\n",
    "ax.fill_between(t_pred, mu-std, mu+std, label='Confidence region', alpha=0.3)\n",
    "ax.set_xlim(1590, 1590+1)\n",
    "#ax.set_ylim(0.992, 0.998)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_power = gp.kernel.get_psd(2*np.pi*f) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_analytic = pg_noise.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_analytic.power = this_power*pg_noise.power.unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the $S/N$ on the periodogram of GP draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lc_draw = lc.copy()\n",
    "many_draw = []\n",
    "for i in range(100):\n",
    "    lc_draw.flux = gp.sample()\n",
    "    pg_draw = lc_draw.to_periodogram(normalization='psd', freq_unit=1/u.day, oversample_factor=10)\n",
    "    many_draw.append(pg_draw.power)\n",
    "    \n",
    "pg_draw.power = np.median(np.array(many_draw), axis=0)*pg_draw.power.unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pg.plot(scale='log')\n",
    "ax.axvline(1.0/guess_period, color='#ddaaaa', linestyle='dotted', label='{:0.3f} d'.format(guess_period), alpha=1)\n",
    "pg_draw.plot(ax=ax, label='GP Draw', scale='log')\n",
    "ax.step(pg.frequency, this_power, color='#f39c12', lw=2,label=\"Analytic model\", where='mid', zorder=0)\n",
    "\n",
    "#ax.plot(f, power_sho1, color='#f39c12', lw=1,label=\"SHO 1\", linestyle='--')\n",
    "#ax.plot(f, power_sho2, color='#f39c12', lw=1,label=\"SHO 2\", linestyle=':')\n",
    "#ax.plot(f, power_mat, color='#f39c12', lw=1,label=\"Matern\", linestyle='-.')\n",
    "\n",
    "plt.ylim(med.mean()/3)\n",
    "ax.set_xlim(pg.frequency[0].value, pg.frequency[-1].value);\n",
    "plt.legend(loc='best')\n",
    "ax.set_xlim(2, 13)\n",
    "plt.title('Posterior PSD');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, to be continued!  There really is structure there above-and-beyond windowing effects.  The True TESS lightcurve does share resemble exactly the same SHO wings of our simple heuristic model.  This discrepancy suggests there is not a continuum of phases (or periods), but a structure phase distribution (or a-symmetric, discrete period distribution).  I think the next steps are:\n",
    "\n",
    "### 1. Model more periods  \n",
    "Possibly most of the micro-periods we see here should get their own SHO (and prior to keep it stable).\n",
    "\n",
    "### 2. Make a differential rotation model with Starry  \n",
    "We seek a generative model for the data, especially one that can inform spectroscopy.  Unfortunately making such a differential rotation map is unproven technology.\n",
    "\n",
    "### 3. Explore resonance beat phenomenon  \n",
    "Two similarly rotating periods should cause a beat phenomenon.  Can we see it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
